timestamp,message,logStreamName
1709607919745,"Collecting git+https://github.com/facebookresearch/detectron2.git (from -r /opt/ml/model/code/requirements.txt (line 2))
  Cloning https://github.com/facebookresearch/detectron2.git to /home/model-server/tmp/pip-req-build-beppji4f
  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /home/model-server/tmp/pip-req-build-beppji4f
  Resolved https://github.com/facebookresearch/detectron2.git to commit 10d074bfecc81653548511bf6eb903942ef32988
  Preparing metadata (setup.py): started",AllTraffic/i-029848aa687347ecd
1709607920505,  Preparing metadata (setup.py): finished with status 'done',AllTraffic/i-029848aa687347ecd
1709607925114,"Collecting git+https://github.com/facebookresearch/detectron2@main#subdirectory=projects/DensePose (from -r /opt/ml/model/code/requirements.txt (line 3))
  Cloning https://github.com/facebookresearch/detectron2 (to revision main) to /home/model-server/tmp/pip-req-build-dww6qy1g
  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2 /home/model-server/tmp/pip-req-build-dww6qy1g
  Resolved https://github.com/facebookresearch/detectron2 to commit 10d074bfecc81653548511bf6eb903942ef32988
  Preparing metadata (setup.py): started",AllTraffic/i-029848aa687347ecd
1709607926532,  Preparing metadata (setup.py): finished with status 'done',AllTraffic/i-029848aa687347ecd
1709607926782,"Collecting sagemaker>=2.199 (from -r /opt/ml/model/code/requirements.txt (line 1))
  Downloading sagemaker-2.210.0-py3-none-any.whl.metadata (13 kB)",AllTraffic/i-029848aa687347ecd
1709607926782,"Collecting av (from -r /opt/ml/model/code/requirements.txt (line 4))
  Downloading av-11.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)",AllTraffic/i-029848aa687347ecd
1709607926782,Requirement already satisfied: sagemaker-inference in /opt/conda/lib/python3.10/site-packages (from -r /opt/ml/model/code/requirements.txt (line 5)) (1.10.1),AllTraffic/i-029848aa687347ecd
1709607927284,"Collecting attrs<24,>=23.1.0 (from sagemaker>=2.199->-r /opt/ml/model/code/requirements.txt (line 1))
  Downloading attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)",AllTraffic/i-029848aa687347ecd
1709607927284,"Collecting boto3<2.0,>=1.33.3 (from sagemaker>=2.199->-r /opt/ml/model/code/requirements.txt (line 1))
  Downloading boto3-1.34.55-py3-none-any.whl.metadata (6.6 kB)",AllTraffic/i-029848aa687347ecd
1709607927284,"Collecting cloudpickle==2.2.1 (from sagemaker>=2.199->-r /opt/ml/model/code/requirements.txt (line 1))
  Downloading cloudpickle-2.2.1-py3-none-any.whl.metadata (6.9 kB)",AllTraffic/i-029848aa687347ecd
1709607927284,"Collecting google-pasta (from sagemaker>=2.199->-r /opt/ml/model/code/requirements.txt (line 1))
  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)",AllTraffic/i-029848aa687347ecd
1709607927535,"Requirement already satisfied: numpy<2.0,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker>=2.199->-r /opt/ml/model/code/requirements.txt (line 1)) (1.22.4)",AllTraffic/i-029848aa687347ecd
1709607927535,"Collecting protobuf<5.0,>=3.12 (from sagemaker>=2.199->-r /opt/ml/model/code/requirements.txt (line 1))
  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)",AllTraffic/i-029848aa687347ecd
1709607927535,"Collecting smdebug-rulesconfig==1.0.1 (from sagemaker>=2.199->-r /opt/ml/model/code/requirements.txt (line 1))
  Downloading smdebug_rulesconfig-1.0.1-py2.py3-none-any.whl.metadata (943 bytes)",AllTraffic/i-029848aa687347ecd
1709607927789,"Collecting importlib-metadata<7.0,>=1.4.0 (from sagemaker>=2.199->-r /opt/ml/model/code/requirements.txt (line 1))
  Downloading importlib_metadata-6.11.0-py3-none-any.whl.metadata (4.9 kB)",AllTraffic/i-029848aa687347ecd
1709607927789,Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker>=2.199->-r /opt/ml/model/code/requirements.txt (line 1)) (23.1),AllTraffic/i-029848aa687347ecd
1709607927789,Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from sagemaker>=2.199->-r /opt/ml/model/code/requirements.txt (line 1)) (1.5.1),AllTraffic/i-029848aa687347ecd
1709607927789,"Collecting pathos (from sagemaker>=2.199->-r /opt/ml/model/code/requirements.txt (line 1))
  Downloading pathos-0.3.2-py3-none-any.whl.metadata (11 kB)",AllTraffic/i-029848aa687347ecd
1709607927789,"Collecting schema (from sagemaker>=2.199->-r /opt/ml/model/code/requirements.txt (line 1))
  Downloading schema-0.7.5-py2.py3-none-any.whl.metadata (34 kB)",AllTraffic/i-029848aa687347ecd
1709607927789,Requirement already satisfied: PyYAML~=6.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker>=2.199->-r /opt/ml/model/code/requirements.txt (line 1)) (6.0),AllTraffic/i-029848aa687347ecd
1709607927789,"Collecting jsonschema (from sagemaker>=2.199->-r /opt/ml/model/code/requirements.txt (line 1))
  Downloading jsonschema-4.21.1-py3-none-any.whl.metadata (7.8 kB)",AllTraffic/i-029848aa687347ecd
1709607927789,"Collecting platformdirs (from sagemaker>=2.199->-r /opt/ml/model/code/requirements.txt (line 1))
  Downloading platformdirs-4.2.0-py3-none-any.whl.metadata (11 kB)",AllTraffic/i-029848aa687347ecd
1709607927789,"Collecting tblib<3,>=1.7.0 (from sagemaker>=2.199->-r /opt/ml/model/code/requirements.txt (line 1))
  Downloading tblib-2.0.0-py3-none-any.whl.metadata (25 kB)",AllTraffic/i-029848aa687347ecd
1709607927789,"Requirement already satisfied: urllib3<3.0.0,>=1.26.8 in /opt/conda/lib/python3.10/site-packages (from sagemaker>=2.199->-r /opt/ml/model/code/requirements.txt (line 1)) (2.0.7)",AllTraffic/i-029848aa687347ecd
1709607927789,Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from sagemaker>=2.199->-r /opt/ml/model/code/requirements.txt (line 1)) (2.31.0),AllTraffic/i-029848aa687347ecd
1709607927789,"Collecting docker (from sagemaker>=2.199->-r /opt/ml/model/code/requirements.txt (line 1))
  Downloading docker-7.0.0-py3-none-any.whl.metadata (3.5 kB)",AllTraffic/i-029848aa687347ecd
1709607927789,Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sagemaker>=2.199->-r /opt/ml/model/code/requirements.txt (line 1)) (4.64.1),AllTraffic/i-029848aa687347ecd
1709607928040,Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from sagemaker>=2.199->-r /opt/ml/model/code/requirements.txt (line 1)) (5.9.5),AllTraffic/i-029848aa687347ecd
1709607928040,Requirement already satisfied: Pillow>=7.1 in /opt/conda/lib/python3.10/site-packages (from detectron2==0.6->-r /opt/ml/model/code/requirements.txt (line 2)) (10.1.0),AllTraffic/i-029848aa687347ecd
1709607928040,Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from detectron2==0.6->-r /opt/ml/model/code/requirements.txt (line 2)) (3.8.1),AllTraffic/i-029848aa687347ecd
1709607928040,"Collecting pycocotools>=2.0.2 (from detectron2==0.6->-r /opt/ml/model/code/requirements.txt (line 2))
  Downloading pycocotools-2.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)",AllTraffic/i-029848aa687347ecd
1709607928040,Requirement already satisfied: termcolor>=1.1 in /opt/conda/lib/python3.10/site-packages (from detectron2==0.6->-r /opt/ml/model/code/requirements.txt (line 2)) (2.3.0),AllTraffic/i-029848aa687347ecd
1709607928040,"Collecting yacs>=0.1.8 (from detectron2==0.6->-r /opt/ml/model/code/requirements.txt (line 2))
  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)",AllTraffic/i-029848aa687347ecd
1709607928040,Requirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from detectron2==0.6->-r /opt/ml/model/code/requirements.txt (line 2)) (0.9.0),AllTraffic/i-029848aa687347ecd
1709607928040,"Collecting tensorboard (from detectron2==0.6->-r /opt/ml/model/code/requirements.txt (line 2))
  Downloading tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)",AllTraffic/i-029848aa687347ecd
1709607928541,"Collecting fvcore<0.1.6,>=0.1.5 (from detectron2==0.6->-r /opt/ml/model/code/requirements.txt (line 2))
  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.2/50.2 kB 7.9 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'",AllTraffic/i-029848aa687347ecd
1709607928541,"Collecting iopath<0.1.10,>=0.1.7 (from detectron2==0.6->-r /opt/ml/model/code/requirements.txt (line 2))
  Downloading iopath-0.1.9-py3-none-any.whl.metadata (370 bytes)",AllTraffic/i-029848aa687347ecd
1709607928541,"Collecting omegaconf<2.4,>=2.1 (from detectron2==0.6->-r /opt/ml/model/code/requirements.txt (line 2))
  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)",AllTraffic/i-029848aa687347ecd
1709607928541,"Collecting hydra-core>=1.1 (from detectron2==0.6->-r /opt/ml/model/code/requirements.txt (line 2))
  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)",AllTraffic/i-029848aa687347ecd
1709607928792,"Collecting black (from detectron2==0.6->-r /opt/ml/model/code/requirements.txt (line 2))
  Downloading black-24.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (74 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 74.6/74.6 kB 12.2 MB/s eta 0:00:00",AllTraffic/i-029848aa687347ecd
1709607928792,"Collecting opencv-python-headless>=4.5.3.56 (from detectron2-densepose==0.6->-r /opt/ml/model/code/requirements.txt (line 3))
  Downloading opencv_python_headless-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)",AllTraffic/i-029848aa687347ecd
1709607928792,Requirement already satisfied: scipy>=1.5.4 in /opt/conda/lib/python3.10/site-packages (from detectron2-densepose==0.6->-r /opt/ml/model/code/requirements.txt (line 3)) (1.11.3),AllTraffic/i-029848aa687347ecd
1709607928792,Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from sagemaker-inference->-r /opt/ml/model/code/requirements.txt (line 5)) (1.16.0),AllTraffic/i-029848aa687347ecd
1709607929294,"Requirement already satisfied: retrying<1.4,>=1.3.3 in /opt/conda/lib/python3.10/site-packages (from sagemaker-inference->-r /opt/ml/model/code/requirements.txt (line 5)) (1.3.4)",AllTraffic/i-029848aa687347ecd
1709607929294,"Collecting botocore<1.35.0,>=1.34.55 (from boto3<2.0,>=1.33.3->sagemaker>=2.199->-r /opt/ml/model/code/requirements.txt (line 1))
  Downloading botocore-1.34.55-py3-none-any.whl.metadata (5.7 kB)",AllTraffic/i-029848aa687347ecd
1709607929294,"Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3<2.0,>=1.33.3->sagemaker>=2.199->-r /opt/ml/model/code/requirements.txt (line 1)) (1.0.1)",AllTraffic/i-029848aa687347ecd
1709607929294,"Collecting s3transfer<0.11.0,>=0.10.0 (from boto3<2.0,>=1.33.3->sagemaker>=2.199->-r /opt/ml/model/code/requirements.txt (line 1))
  Downloading s3transfer-0.10.0-py3-none-any.whl.metadata (1.7 kB)",AllTraffic/i-029848aa687347ecd
1709607929795,"Collecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.1->detectron2==0.6->-r /opt/ml/model/code/requirements.txt (line 2))
  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 117.0/117.0 kB 20.2 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'",AllTraffic/i-029848aa687347ecd
1709607929795,"Collecting zipp>=0.5 (from importlib-metadata<7.0,>=1.4.0->sagemaker>=2.199->-r /opt/ml/model/code/requirements.txt (line 1))
  Downloading zipp-3.17.0-py3-none-any.whl.metadata (3.7 kB)",AllTraffic/i-029848aa687347ecd
1709607929795,"Collecting portalocker (from iopath<0.1.10,>=0.1.7->detectron2==0.6->-r /opt/ml/model/code/requirements.txt (line 2))
  Downloading portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)",AllTraffic/i-029848aa687347ecd
1709607929795,Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->detectron2==0.6->-r /opt/ml/model/code/requirements.txt (line 2)) (1.2.0),AllTraffic/i-029848aa687347ecd
1709607929795,Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->detectron2==0.6->-r /opt/ml/model/code/requirements.txt (line 2)) (0.12.1),AllTraffic/i-029848aa687347ecd
1709607929795,Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->detectron2==0.6->-r /opt/ml/model/code/requirements.txt (line 2)) (4.44.0),AllTraffic/i-029848aa687347ecd
1709607929795,Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->detectron2==0.6->-r /opt/ml/model/code/requirements.txt (line 2)) (1.4.5),AllTraffic/i-029848aa687347ecd
1709607929795,Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->detectron2==0.6->-r /opt/ml/model/code/requirements.txt (line 2)) (3.1.1),AllTraffic/i-029848aa687347ecd
1709607930045,Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->detectron2==0.6->-r /opt/ml/model/code/requirements.txt (line 2)) (2.8.2),AllTraffic/i-029848aa687347ecd
1709607930045,Requirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from black->detectron2==0.6->-r /opt/ml/model/code/requirements.txt (line 2)) (8.1.7),AllTraffic/i-029848aa687347ecd
1709607930045,"Collecting mypy-extensions>=0.4.3 (from black->detectron2==0.6->-r /opt/ml/model/code/requirements.txt (line 2))
  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)",AllTraffic/i-029848aa687347ecd
1709607930045,"Collecting pathspec>=0.9.0 (from black->detectron2==0.6->-r /opt/ml/model/code/requirements.txt (line 2))
  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)",AllTraffic/i-029848aa687347ecd
1709607930045,"Collecting tomli>=1.1.0 (from black->detectron2==0.6->-r /opt/ml/model/code/requirements.txt (line 2))
  Downloading tomli-2.0.1-py3-none-any.whl.metadata (8.9 kB)",AllTraffic/i-029848aa687347ecd
1709607930045,Requirement already satisfied: typing-extensions>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from black->detectron2==0.6->-r /opt/ml/model/code/requirements.txt (line 2)) (4.8.0),AllTraffic/i-029848aa687347ecd
1709607930045,"Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->sagemaker>=2.199->-r /opt/ml/model/code/requirements.txt (line 1)) (3.3.2)",AllTraffic/i-029848aa687347ecd
1709607930045,"Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->sagemaker>=2.199->-r /opt/ml/model/code/requirements.txt (line 1)) (3.4)",AllTraffic/i-029848aa687347ecd
1709607930045,Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->sagemaker>=2.199->-r /opt/ml/model/code/requirements.txt (line 1)) (2023.7.22),AllTraffic/i-029848aa687347ecd
1709607930296,"Collecting jsonschema-specifications>=2023.03.6 (from jsonschema->sagemaker>=2.199->-r /opt/ml/model/code/requirements.txt (line 1))
  Downloading jsonschema_specifications-2023.12.1-py3-none-any.whl.metadata (3.0 kB)",AllTraffic/i-029848aa687347ecd
1709607930547,"Collecting referencing>=0.28.4 (from jsonschema->sagemaker>=2.199->-r /opt/ml/model/code/requirements.txt (line 1))
  Downloading referencing-0.33.0-py3-none-any.whl.metadata (2.7 kB)",AllTraffic/i-029848aa687347ecd
1709607930547,"Collecting rpds-py>=0.7.1 (from jsonschema->sagemaker>=2.199->-r /opt/ml/model/code/requirements.txt (line 1))
  Downloading rpds_py-0.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)",AllTraffic/i-029848aa687347ecd
1709607930547,Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->sagemaker>=2.199->-r /opt/ml/model/code/requirements.txt (line 1)) (2022.6),AllTraffic/i-029848aa687347ecd
1709607930547,"Collecting ppft>=1.7.6.8 (from pathos->sagemaker>=2.199->-r /opt/ml/model/code/requirements.txt (line 1))
  Downloading ppft-1.7.6.8-py3-none-any.whl.metadata (12 kB)",AllTraffic/i-029848aa687347ecd
1709607930547,"Collecting dill>=0.3.8 (from pathos->sagemaker>=2.199->-r /opt/ml/model/code/requirements.txt (line 1))
  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)",AllTraffic/i-029848aa687347ecd
1709607930547,"Collecting pox>=0.3.4 (from pathos->sagemaker>=2.199->-r /opt/ml/model/code/requirements.txt (line 1))
  Downloading pox-0.3.4-py3-none-any.whl.metadata (8.0 kB)",AllTraffic/i-029848aa687347ecd
1709607930547,"Collecting multiprocess>=0.70.16 (from pathos->sagemaker>=2.199->-r /opt/ml/model/code/requirements.txt (line 1))
  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)",AllTraffic/i-029848aa687347ecd
1709607930547,"Collecting contextlib2>=0.5.5 (from schema->sagemaker>=2.199->-r /opt/ml/model/code/requirements.txt (line 1))
  Downloading contextlib2-21.6.0-py2.py3-none-any.whl.metadata (4.1 kB)",AllTraffic/i-029848aa687347ecd
1709607931299,"Collecting absl-py>=0.4 (from tensorboard->detectron2==0.6->-r /opt/ml/model/code/requirements.txt (line 2))
  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)",AllTraffic/i-029848aa687347ecd
1709607931299,"Collecting grpcio>=1.48.2 (from tensorboard->detectron2==0.6->-r /opt/ml/model/code/requirements.txt (line 2))
  Downloading grpcio-1.62.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)",AllTraffic/i-029848aa687347ecd
1709607931299,"Collecting markdown>=2.6.8 (from tensorboard->detectron2==0.6->-r /opt/ml/model/code/requirements.txt (line 2))
  Downloading Markdown-3.5.2-py3-none-any.whl.metadata (7.0 kB)",AllTraffic/i-029848aa687347ecd
1709607931299,Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard->detectron2==0.6->-r /opt/ml/model/code/requirements.txt (line 2)) (65.6.3),AllTraffic/i-029848aa687347ecd
1709607931299,"Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard->detectron2==0.6->-r /opt/ml/model/code/requirements.txt (line 2))
  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)",AllTraffic/i-029848aa687347ecd
1709607931801,Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard->detectron2==0.6->-r /opt/ml/model/code/requirements.txt (line 2)) (3.0.1),AllTraffic/i-029848aa687347ecd
1709607931801,Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard->detectron2==0.6->-r /opt/ml/model/code/requirements.txt (line 2)) (2.1.3),AllTraffic/i-029848aa687347ecd
1709607931801,"Downloading sagemaker-2.210.0-py3-none-any.whl (1.4 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.4/1.4 MB 21.7 MB/s eta 0:00:00",AllTraffic/i-029848aa687347ecd
1709607931801,Downloading cloudpickle-2.2.1-py3-none-any.whl (25 kB),AllTraffic/i-029848aa687347ecd
1709607931801,Downloading smdebug_rulesconfig-1.0.1-py2.py3-none-any.whl (20 kB),AllTraffic/i-029848aa687347ecd
1709607932302,"Downloading av-11.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32.9 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 32.9/32.9 MB 40.9 MB/s eta 0:00:00",AllTraffic/i-029848aa687347ecd
1709607932302,"Downloading attrs-23.2.0-py3-none-any.whl (60 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.8/60.8 kB 10.1 MB/s eta 0:00:00",AllTraffic/i-029848aa687347ecd
1709607932302,"Downloading boto3-1.34.55-py3-none-any.whl (139 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 139.3/139.3 kB 22.2 MB/s eta 0:00:00",AllTraffic/i-029848aa687347ecd
1709607932302,"Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 154.5/154.5 kB 20.6 MB/s eta 0:00:00",AllTraffic/i-029848aa687347ecd
1709607932302,Downloading importlib_metadata-6.11.0-py3-none-any.whl (23 kB),AllTraffic/i-029848aa687347ecd
1709607932302,Downloading iopath-0.1.9-py3-none-any.whl (27 kB),AllTraffic/i-029848aa687347ecd
1709607932302,"Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.5/79.5 kB 13.4 MB/s eta 0:00:00",AllTraffic/i-029848aa687347ecd
1709607932803,"Downloading opencv_python_headless-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.6 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 49.6/49.6 MB 28.8 MB/s eta 0:00:00",AllTraffic/i-029848aa687347ecd
1709607932803,"Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 294.6/294.6 kB 31.7 MB/s eta 0:00:00",AllTraffic/i-029848aa687347ecd
1709607932803,"Downloading pycocotools-2.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (426 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 426.2/426.2 kB 40.8 MB/s eta 0:00:00",AllTraffic/i-029848aa687347ecd
1709607932803,Downloading tblib-2.0.0-py3-none-any.whl (11 kB),AllTraffic/i-029848aa687347ecd
1709607932803,Downloading yacs-0.1.8-py3-none-any.whl (14 kB),AllTraffic/i-029848aa687347ecd
1709607933054,"Downloading black-24.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.7/1.7 MB 69.0 MB/s eta 0:00:00",AllTraffic/i-029848aa687347ecd
1709607933054,Downloading platformdirs-4.2.0-py3-none-any.whl (17 kB),AllTraffic/i-029848aa687347ecd
1709607933054,"Downloading docker-7.0.0-py3-none-any.whl (147 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 147.6/147.6 kB 20.6 MB/s eta 0:00:00",AllTraffic/i-029848aa687347ecd
1709607933054,"Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.5/57.5 kB 9.5 MB/s eta 0:00:00",AllTraffic/i-029848aa687347ecd
1709607933054,"Downloading jsonschema-4.21.1-py3-none-any.whl (85 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 85.5/85.5 kB 13.8 MB/s eta 0:00:00",AllTraffic/i-029848aa687347ecd
1709607933054,"Downloading pathos-0.3.2-py3-none-any.whl (82 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 82.1/82.1 kB 9.8 MB/s eta 0:00:00",AllTraffic/i-029848aa687347ecd
1709607933054,Downloading schema-0.7.5-py2.py3-none-any.whl (17 kB),AllTraffic/i-029848aa687347ecd
1709607933054,"Downloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.5/5.5 MB 86.2 MB/s eta 0:00:00",AllTraffic/i-029848aa687347ecd
1709607933054,"Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 133.7/133.7 kB 19.3 MB/s eta 0:00:00",AllTraffic/i-029848aa687347ecd
1709607933305,"Downloading botocore-1.34.55-py3-none-any.whl (12.0 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.0/12.0 MB 83.0 MB/s eta 0:00:00",AllTraffic/i-029848aa687347ecd
1709607933305,Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB),AllTraffic/i-029848aa687347ecd
1709607933305,"Downloading dill-0.3.8-py3-none-any.whl (116 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 116.3/116.3 kB 18.7 MB/s eta 0:00:00",AllTraffic/i-029848aa687347ecd
1709607933305,"Downloading grpcio-1.62.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.5 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.5/5.5 MB 87.8 MB/s eta 0:00:00",AllTraffic/i-029848aa687347ecd
1709607933305,Downloading jsonschema_specifications-2023.12.1-py3-none-any.whl (18 kB),AllTraffic/i-029848aa687347ecd
1709607933305,"Downloading Markdown-3.5.2-py3-none-any.whl (103 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 103.9/103.9 kB 13.7 MB/s eta 0:00:00",AllTraffic/i-029848aa687347ecd
1709607933305,"Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.8/134.8 kB 20.2 MB/s eta 0:00:00",AllTraffic/i-029848aa687347ecd
1709607933305,Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB),AllTraffic/i-029848aa687347ecd
1709607933305,Downloading pathspec-0.12.1-py3-none-any.whl (31 kB),AllTraffic/i-029848aa687347ecd
1709607933305,Downloading pox-0.3.4-py3-none-any.whl (29 kB),AllTraffic/i-029848aa687347ecd
1709607933556,"Downloading ppft-1.7.6.8-py3-none-any.whl (56 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.8/56.8 kB 1.2 MB/s eta 0:00:00",AllTraffic/i-029848aa687347ecd
1709607933556,Downloading referencing-0.33.0-py3-none-any.whl (26 kB),AllTraffic/i-029848aa687347ecd
1709607933556,"Downloading rpds_py-0.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 68.9 MB/s eta 0:00:00",AllTraffic/i-029848aa687347ecd
1709607933556,"Downloading s3transfer-0.10.0-py3-none-any.whl (82 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 82.1/82.1 kB 11.2 MB/s eta 0:00:00",AllTraffic/i-029848aa687347ecd
1709607933556,"Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.6/6.6 MB 81.4 MB/s eta 0:00:00",AllTraffic/i-029848aa687347ecd
1709607933556,Downloading tomli-2.0.1-py3-none-any.whl (12 kB),AllTraffic/i-029848aa687347ecd
1709607933556,Downloading zipp-3.17.0-py3-none-any.whl (7.4 kB),AllTraffic/i-029848aa687347ecd
1709607934057,Downloading portalocker-2.8.2-py3-none-any.whl (17 kB),AllTraffic/i-029848aa687347ecd
1709607938745,"Building wheels for collected packages: detectron2, detectron2-densepose, fvcore, antlr4-python3-runtime
  Building wheel for detectron2 (setup.py): started",AllTraffic/i-029848aa687347ecd
1709607998745,  Building wheel for detectron2 (setup.py): still running...,AllTraffic/i-029848aa687347ecd
1709608061745,  Building wheel for detectron2 (setup.py): still running...,AllTraffic/i-029848aa687347ecd
1709608124745,  Building wheel for detectron2 (setup.py): still running...,AllTraffic/i-029848aa687347ecd
1709608192745,  Building wheel for detectron2 (setup.py): still running...,AllTraffic/i-029848aa687347ecd
1709608254745,  Building wheel for detectron2 (setup.py): still running...,AllTraffic/i-029848aa687347ecd
1709608269745,"  Building wheel for detectron2 (setup.py): finished with status 'done'
  Created wheel for detectron2: filename=detectron2-0.6-cp310-cp310-linux_x86_64.whl size=1866436 sha256=48eb6b1b6bd067d1a24b67aab30ff557e35902989414d3fcb768c5a4f4021aa6
  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-0itu2eii/wheels/47/e5/15/94c80df2ba85500c5d76599cc307c0a7079d0e221bb6fc4375
  Building wheel for detectron2-densepose (setup.py): started",AllTraffic/i-029848aa687347ecd
1709608270970,"  Building wheel for detectron2-densepose (setup.py): finished with status 'done'
  Created wheel for detectron2-densepose: filename=detectron2_densepose-0.6-py3-none-any.whl size=176959 sha256=b233ce45f71492a1945f029e987629990dd065131b2685a166436abf3578b71e
  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-0itu2eii/wheels/b0/98/56/b28f701cfab811368abde18628e7d23cf474928f6fc8a9e5ee
  Building wheel for fvcore (setup.py): started
  Building wheel for fvcore (setup.py): finished with status 'done'
  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61405 sha256=4586935122f23fb9085a3bd83243e6bf40c2d7e3487bcc55eb51fd2291d1714e
  Stored in directory: /root/.cache/pip/wheels/01/c0/af/77c1cf53a1be9e42a52b48e5af2169d40ec2e89f7362489dd0
  Building wheel for antlr4-python3-runtime (setup.py): started
  Building wheel for antlr4-python3-runtime (setup.py): finished with status 'done'
  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=28140e751d7e239eed205d56666dfef4ad4a782ca545ba1b387e56f1869290e8
  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88",AllTraffic/i-029848aa687347ecd
1709608271471,Successfully built detectron2 detectron2-densepose fvcore antlr4-python3-runtime,AllTraffic/i-029848aa687347ecd
1709608275745,"Installing collected packages: antlr4-python3-runtime, zipp, yacs, tomli, tensorboard-data-server, tblib, smdebug-rulesconfig, rpds-py, protobuf, ppft, pox, portalocker, platformdirs, pathspec, opencv-python-headless, omegaconf, mypy-extensions, markdown, grpcio, google-pasta, dill, contextlib2, cloudpickle, av, attrs, absl-py, tensorboard, schema, referencing, multiprocess, iopath, importlib-metadata, hydra-core, docker, botocore, black, s3transfer, pycocotools, pathos, jsonschema-specifications, fvcore, jsonschema, detectron2, boto3, sagemaker, detectron2-densepose
  Attempting uninstall: botocore
    Found existing installation: botocore 1.31.78
    Uninstalling botocore-1.31.78:
      Successfully uninstalled botocore-1.31.78",AllTraffic/i-029848aa687347ecd
1709608277488,"  Attempting uninstall: s3transfer
    Found existing installation: s3transfer 0.7.0
    Uninstalling s3transfer-0.7.0:
      Successfully uninstalled s3transfer-0.7.0
  Attempting uninstall: boto3
    Found existing installation: boto3 1.28.78
    Uninstalling boto3-1.28.78:
      Successfully uninstalled boto3-1.28.78",AllTraffic/i-029848aa687347ecd
1709608277488,ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.,AllTraffic/i-029848aa687347ecd
1709608277488,"awscli 1.29.78 requires botocore==1.31.78, but you have botocore 1.34.55 which is incompatible.",AllTraffic/i-029848aa687347ecd
1709608277488,"awscli 1.29.78 requires s3transfer<0.8.0,>=0.7.0, but you have s3transfer 0.10.0 which is incompatible.",AllTraffic/i-029848aa687347ecd
1709608277488,Successfully installed absl-py-2.1.0 antlr4-python3-runtime-4.9.3 attrs-23.2.0 av-11.0.0 black-24.2.0 boto3-1.34.55 botocore-1.34.55 cloudpickle-2.2.1 contextlib2-21.6.0 detectron2-0.6 detectron2-densepose-0.6 dill-0.3.8 docker-7.0.0 fvcore-0.1.5.post20221221 google-pasta-0.2.0 grpcio-1.62.0 hydra-core-1.3.2 importlib-metadata-6.11.0 iopath-0.1.9 jsonschema-4.21.1 jsonschema-specifications-2023.12.1 markdown-3.5.2 multiprocess-0.70.16 mypy-extensions-1.0.0 omegaconf-2.3.0 opencv-python-headless-4.9.0.80 pathos-0.3.2 pathspec-0.12.1 platformdirs-4.2.0 portalocker-2.8.2 pox-0.3.4 ppft-1.7.6.8 protobuf-4.25.3 pycocotools-2.0.7 referencing-0.33.0 rpds-py-0.18.0 s3transfer-0.10.0 sagemaker-2.210.0 schema-0.7.5 smdebug-rulesconfig-1.0.1 tblib-2.0.0 tensorboard-2.16.2 tensorboard-data-server-0.7.2 tomli-2.0.1 yacs-0.1.8 zipp-3.17.0,AllTraffic/i-029848aa687347ecd
1709608277488,WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv,AllTraffic/i-029848aa687347ecd
1709608277488,[notice] A new release of pip is available: 23.3.1 -> 24.0,AllTraffic/i-029848aa687347ecd
1709608278241,"[notice] To update, run: pip install --upgrade pip",AllTraffic/i-029848aa687347ecd
1709608278492,Warning: TorchServe is using non-default JVM parameters: -XX:-UseContainerSupport,AllTraffic/i-029848aa687347ecd
1709608279242,WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.,AllTraffic/i-029848aa687347ecd
1709608279242,"2024-03-05T03:11:19,012 [WARN ] main org.pytorch.serve.util.ConfigManager - Your torchserve instance can access any URL to load models. When deploying to production, make sure to limit the set of allowed_urls in config.properties",AllTraffic/i-029848aa687347ecd
1709608279242,"2024-03-05T03:11:19,015 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...",AllTraffic/i-029848aa687347ecd
1709608279242,"2024-03-05T03:11:19,081 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml",AllTraffic/i-029848aa687347ecd
1709608279242,"2024-03-05T03:11:19,186 [INFO ] main org.pytorch.serve.ModelServer - ",AllTraffic/i-029848aa687347ecd
1709608279242,Torchserve version: 0.8.2,AllTraffic/i-029848aa687347ecd
1709608279242,TS Home: /opt/conda/lib/python3.10/site-packages,AllTraffic/i-029848aa687347ecd
1709608279242,Current directory: /,AllTraffic/i-029848aa687347ecd
1709608279242,Temp directory: /home/model-server/tmp,AllTraffic/i-029848aa687347ecd
1709608279242,Metrics config path: /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml,AllTraffic/i-029848aa687347ecd
1709608279242,Number of GPUs: 1,AllTraffic/i-029848aa687347ecd
1709608279242,Number of CPUs: 4,AllTraffic/i-029848aa687347ecd
1709608279242,Max heap size: 3934 M,AllTraffic/i-029848aa687347ecd
1709608279242,Python executable: /opt/conda/bin/python3.10,AllTraffic/i-029848aa687347ecd
1709608279242,Config file: /etc/sagemaker-ts.properties,AllTraffic/i-029848aa687347ecd
1709608279242,Inference address: http://0.0.0.0:8080,AllTraffic/i-029848aa687347ecd
1709608279242,Management address: http://0.0.0.0:8080,AllTraffic/i-029848aa687347ecd
1709608279242,Metrics address: http://127.0.0.1:8082,AllTraffic/i-029848aa687347ecd
1709608279242,Model Store: /.sagemaker/ts/models,AllTraffic/i-029848aa687347ecd
1709608279242,Initial Models: model=/opt/ml/model,AllTraffic/i-029848aa687347ecd
1709608279242,Log dir: /logs,AllTraffic/i-029848aa687347ecd
1709608279242,Metrics dir: /logs,AllTraffic/i-029848aa687347ecd
1709608279242,Netty threads: 0,AllTraffic/i-029848aa687347ecd
1709608279242,Netty client threads: 0,AllTraffic/i-029848aa687347ecd
1709608279242,Default workers per model: 1,AllTraffic/i-029848aa687347ecd
1709608279242,Blacklist Regex: N/A,AllTraffic/i-029848aa687347ecd
1709608279242,Maximum Response Size: 6553500,AllTraffic/i-029848aa687347ecd
1709608279242,Maximum Request Size: 6553500,AllTraffic/i-029848aa687347ecd
1709608279242,Limit Maximum Image Pixels: true,AllTraffic/i-029848aa687347ecd
1709608279242,Prefer direct buffer: false,AllTraffic/i-029848aa687347ecd
1709608279242,Allowed Urls: [file://.*|http(s)?://.*],AllTraffic/i-029848aa687347ecd
1709608279242,Custom python dependency for model allowed: false,AllTraffic/i-029848aa687347ecd
1709608279242,Enable metrics API: true,AllTraffic/i-029848aa687347ecd
1709608279242,Metrics mode: log,AllTraffic/i-029848aa687347ecd
1709608279242,Disable system metrics: true,AllTraffic/i-029848aa687347ecd
1709608279242,Workflow Store: /.sagemaker/ts/models,AllTraffic/i-029848aa687347ecd
1709608279242,Model config: N/A,AllTraffic/i-029848aa687347ecd
1709608279242,"2024-03-05T03:11:19,193 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...",AllTraffic/i-029848aa687347ecd
1709608279242,"2024-03-05T03:11:19,214 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: /opt/ml/model",AllTraffic/i-029848aa687347ecd
1709608279242,"2024-03-05T03:11:19,217 [WARN ] main org.pytorch.serve.archive.model.ModelArchive - Model archive version is not defined. Please upgrade to torch-model-archiver 0.2.0 or higher",AllTraffic/i-029848aa687347ecd
1709608279242,"2024-03-05T03:11:19,218 [WARN ] main org.pytorch.serve.archive.model.ModelArchive - Model archive createdOn is not defined. Please upgrade to torch-model-archiver 0.2.0 or higher",AllTraffic/i-029848aa687347ecd
1709608279242,"2024-03-05T03:11:19,220 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model model loaded.",AllTraffic/i-029848aa687347ecd
1709608279493,"2024-03-05T03:11:19,230 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.",AllTraffic/i-029848aa687347ecd
1709608279493,"2024-03-05T03:11:19,320 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080",AllTraffic/i-029848aa687347ecd
1709608279493,"2024-03-05T03:11:19,321 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.",AllTraffic/i-029848aa687347ecd
1709608279743,"2024-03-05T03:11:19,325 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082",AllTraffic/i-029848aa687347ecd
1709608279993,Model server started.,AllTraffic/i-029848aa687347ecd
1709608279993,"2024-03-05T03:11:19,913 [INFO ] pool-2-thread-2 ACCESS_LOG - /169.254.178.2:57068 ""GET /ping HTTP/1.1"" 200 14",AllTraffic/i-029848aa687347ecd
1709608280995,"2024-03-05T03:11:19,914 [INFO ] pool-2-thread-2 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:container-0.local,timestamp:1709608279",AllTraffic/i-029848aa687347ecd
1709608280995,"2024-03-05T03:11:20,787 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9000, pid=490",AllTraffic/i-029848aa687347ecd
1709608280995,"2024-03-05T03:11:20,788 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000",AllTraffic/i-029848aa687347ecd
1709608280995,"2024-03-05T03:11:20,804 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.",AllTraffic/i-029848aa687347ecd
1709608280995,"2024-03-05T03:11:20,804 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - [PID]490",AllTraffic/i-029848aa687347ecd
1709608280995,"2024-03-05T03:11:20,804 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Torch worker started.",AllTraffic/i-029848aa687347ecd
1709608280995,"2024-03-05T03:11:20,805 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9",AllTraffic/i-029848aa687347ecd
1709608280995,"2024-03-05T03:11:20,808 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000",AllTraffic/i-029848aa687347ecd
1709608280995,"2024-03-05T03:11:20,814 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.",AllTraffic/i-029848aa687347ecd
1709608280995,"2024-03-05T03:11:20,817 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1709608280817",AllTraffic/i-029848aa687347ecd
1709608281746,"2024-03-05T03:11:20,839 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1",AllTraffic/i-029848aa687347ecd
1709608281746,"2024-03-05T03:11:21,621 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml",AllTraffic/i-029848aa687347ecd
1709608282749,"2024-03-05T03:11:21,622 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml",AllTraffic/i-029848aa687347ecd
1709608282749,"2024-03-05T03:11:22,608 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - [03/05 03:11:22 muscle_part]: Loading config from my_model/densepose_rcnn_R_50_FPN_s1x_legacy.yaml",AllTraffic/i-029848aa687347ecd
1709608282749,"2024-03-05T03:11:22,611 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend worker process died.",AllTraffic/i-029848aa687347ecd
1709608282749,"2024-03-05T03:11:22,612 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):",AllTraffic/i-029848aa687347ecd
1709608282749,"2024-03-05T03:11:22,612 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File ""/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py"", line 253, in <module>",AllTraffic/i-029848aa687347ecd
1709608282749,"2024-03-05T03:11:22,613 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     worker.run_server()",AllTraffic/i-029848aa687347ecd
1709608282749,"2024-03-05T03:11:22,613 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File ""/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py"", line 221, in run_server",AllTraffic/i-029848aa687347ecd
1709608282749,"2024-03-05T03:11:22,614 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)",AllTraffic/i-029848aa687347ecd
1709608282749,"2024-03-05T03:11:22,615 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File ""/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py"", line 184, in handle_connection",AllTraffic/i-029848aa687347ecd
1709608282749,"2024-03-05T03:11:22,615 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)",AllTraffic/i-029848aa687347ecd
1709608282749,"2024-03-05T03:11:22,615 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File ""/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py"", line 131, in load_model",AllTraffic/i-029848aa687347ecd
1709608282749,"2024-03-05T03:11:22,616 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     service = model_loader.load(",AllTraffic/i-029848aa687347ecd
1709608282749,"2024-03-05T03:11:22,616 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File ""/opt/conda/lib/python3.10/site-packages/ts/model_loader.py"", line 135, in load",AllTraffic/i-029848aa687347ecd
1709608282749,"2024-03-05T03:11:22,617 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED",AllTraffic/i-029848aa687347ecd
1709608282749,"2024-03-05T03:11:22,621 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.",AllTraffic/i-029848aa687347ecd
1709608282749,"2024-03-05T03:11:22,621 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1709608282621",AllTraffic/i-029848aa687347ecd
1709608282749,"2024-03-05T03:11:22,621 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stderr",AllTraffic/i-029848aa687347ecd
1709608282749,"2024-03-05T03:11:22,622 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stdout",AllTraffic/i-029848aa687347ecd
1709608282749,"2024-03-05T03:11:22,616 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)",AllTraffic/i-029848aa687347ecd
1709608282749,"2024-03-05T03:11:22,624 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stdout",AllTraffic/i-029848aa687347ecd
1709608284252,"2024-03-05T03:11:22,626 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.",AllTraffic/i-029848aa687347ecd
1709608284252,"2024-03-05T03:11:24,167 [INFO ] W-9000-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stderr",AllTraffic/i-029848aa687347ecd
1709608284252,"2024-03-05T03:11:24,169 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stderr",AllTraffic/i-029848aa687347ecd
1709608284252,"2024-03-05T03:11:24,169 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stdout",AllTraffic/i-029848aa687347ecd
1709608284252,"2024-03-05T03:11:24,177 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stdout",AllTraffic/i-029848aa687347ecd
1709608284252,"2024-03-05T03:11:24,177 [INFO ] W-9000-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stderr",AllTraffic/i-029848aa687347ecd
1709608284253,"2024-03-05T03:11:24,169 [ERROR] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker error",AllTraffic/i-029848aa687347ecd
1709608284253,org.pytorch.serve.wlm.WorkerInitializationException: Backend stream closed.,AllTraffic/i-029848aa687347ecd
1709608284253,#011at org.pytorch.serve.wlm.WorkerLifeCycle.startWorker(WorkerLifeCycle.java:173) ~[model-server.jar:?],AllTraffic/i-029848aa687347ecd
1709608284253,#011at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:339) ~[model-server.jar:?],AllTraffic/i-029848aa687347ecd
1709608284253,#011at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?],AllTraffic/i-029848aa687347ecd
1709608284253,#011at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?],AllTraffic/i-029848aa687347ecd
1709608284253,#011at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?],AllTraffic/i-029848aa687347ecd
1709608284253,#011at java.lang.Thread.run(Thread.java:833) [?:?],AllTraffic/i-029848aa687347ecd
1709608284253,"2024-03-05T03:11:24,198 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again",AllTraffic/i-029848aa687347ecd
1709608284253,"2024-03-05T03:11:24,198 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stderr",AllTraffic/i-029848aa687347ecd
1709608284253,"2024-03-05T03:11:24,198 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stdout",AllTraffic/i-029848aa687347ecd
1709608285004,"2024-03-05T03:11:24,199 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.",AllTraffic/i-029848aa687347ecd
1709608285004,"2024-03-05T03:11:24,826 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.178.2:57068 ""GET /ping HTTP/1.1"" 200 1",AllTraffic/i-029848aa687347ecd
1709608286758,"2024-03-05T03:11:24,826 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:container-0.local,timestamp:1709608284",AllTraffic/i-029848aa687347ecd
1709608286758,"2024-03-05T03:11:26,558 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9000, pid=550",AllTraffic/i-029848aa687347ecd
1709608286758,"2024-03-05T03:11:26,559 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000",AllTraffic/i-029848aa687347ecd
1709608286758,"2024-03-05T03:11:26,576 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.",AllTraffic/i-029848aa687347ecd
1709608286758,"2024-03-05T03:11:26,576 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - [PID]550",AllTraffic/i-029848aa687347ecd
1709608286758,"2024-03-05T03:11:26,577 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Torch worker started.",AllTraffic/i-029848aa687347ecd
1709608286758,"2024-03-05T03:11:26,577 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9",AllTraffic/i-029848aa687347ecd
1709608286758,"2024-03-05T03:11:26,577 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000",AllTraffic/i-029848aa687347ecd
1709608286758,"2024-03-05T03:11:26,582 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED",AllTraffic/i-029848aa687347ecd
1709608286758,"2024-03-05T03:11:26,583 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.",AllTraffic/i-029848aa687347ecd
1709608286758,"2024-03-05T03:11:26,583 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again",AllTraffic/i-029848aa687347ecd
1709608286758,"2024-03-05T03:11:26,584 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stderr",AllTraffic/i-029848aa687347ecd
1709608286758,"2024-03-05T03:11:26,584 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stdout",AllTraffic/i-029848aa687347ecd
1709608290017,"2024-03-05T03:11:26,584 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.",AllTraffic/i-029848aa687347ecd
1709608290017,"2024-03-05T03:11:29,825 [INFO ] pool-2-thread-2 ACCESS_LOG - /169.254.178.2:57068 ""GET /ping HTTP/1.1"" 200 1",AllTraffic/i-029848aa687347ecd
1709608290017,"2024-03-05T03:11:29,825 [INFO ] pool-2-thread-2 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:container-0.local,timestamp:1709608289",AllTraffic/i-029848aa687347ecd
1709608290017,"2024-03-05T03:11:29,842 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stdout",AllTraffic/i-029848aa687347ecd
1709608290017,"2024-03-05T03:11:29,843 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stderr",AllTraffic/i-029848aa687347ecd
1709608290017,"2024-03-05T03:11:29,843 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stdout",AllTraffic/i-029848aa687347ecd
1709608290017,"2024-03-05T03:11:29,843 [ERROR] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker error",AllTraffic/i-029848aa687347ecd
1709608290017,org.pytorch.serve.wlm.WorkerInitializationException: Backend stream closed.,AllTraffic/i-029848aa687347ecd
1709608290017,#011at org.pytorch.serve.wlm.WorkerLifeCycle.startWorker(WorkerLifeCycle.java:173) ~[model-server.jar:?],AllTraffic/i-029848aa687347ecd
1709608290017,#011at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:339) ~[model-server.jar:?],AllTraffic/i-029848aa687347ecd
1709608290017,#011at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?],AllTraffic/i-029848aa687347ecd
1709608290017,#011at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?],AllTraffic/i-029848aa687347ecd
1709608290017,#011at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?],AllTraffic/i-029848aa687347ecd
1709608290017,#011at java.lang.Thread.run(Thread.java:833) [?:?],AllTraffic/i-029848aa687347ecd
1709608290017,"2024-03-05T03:11:29,844 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again",AllTraffic/i-029848aa687347ecd
1709608290017,"2024-03-05T03:11:29,844 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stderr",AllTraffic/i-029848aa687347ecd
1709608290017,"2024-03-05T03:11:29,845 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stdout",AllTraffic/i-029848aa687347ecd
1709608290017,"2024-03-05T03:11:29,845 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.",AllTraffic/i-029848aa687347ecd
1709608290017,"2024-03-05T03:11:29,842 [INFO ] W-9000-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stderr",AllTraffic/i-029848aa687347ecd
1709608290017,"2024-03-05T03:11:29,857 [INFO ] W-9000-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stderr",AllTraffic/i-029848aa687347ecd
1709608294278,"2024-03-05T03:11:29,857 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stdout",AllTraffic/i-029848aa687347ecd
1709608294278,"2024-03-05T03:11:34,173 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9000, pid=568",AllTraffic/i-029848aa687347ecd
1709608294278,"2024-03-05T03:11:34,175 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000",AllTraffic/i-029848aa687347ecd
1709608294278,"2024-03-05T03:11:34,190 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.",AllTraffic/i-029848aa687347ecd
1709608294278,"2024-03-05T03:11:34,191 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - [PID]568",AllTraffic/i-029848aa687347ecd
1709608294278,"2024-03-05T03:11:34,191 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Torch worker started.",AllTraffic/i-029848aa687347ecd
1709608294278,"2024-03-05T03:11:34,191 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000",AllTraffic/i-029848aa687347ecd
1709608294278,"2024-03-05T03:11:34,192 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9",AllTraffic/i-029848aa687347ecd
1709608294278,"2024-03-05T03:11:34,193 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED",AllTraffic/i-029848aa687347ecd
1709608294278,"2024-03-05T03:11:34,193 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.",AllTraffic/i-029848aa687347ecd
1709608294278,"2024-03-05T03:11:34,193 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again",AllTraffic/i-029848aa687347ecd
1709608294278,"2024-03-05T03:11:34,201 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stderr",AllTraffic/i-029848aa687347ecd
1709608294278,"2024-03-05T03:11:34,202 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stdout",AllTraffic/i-029848aa687347ecd
1709608295029,"2024-03-05T03:11:34,202 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 5 seconds.",AllTraffic/i-029848aa687347ecd
1709608295029,"2024-03-05T03:11:34,825 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.178.2:57068 ""GET /ping HTTP/1.1"" 200 0",AllTraffic/i-029848aa687347ecd
1709608297538,"2024-03-05T03:11:34,826 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:container-0.local,timestamp:1709608294",AllTraffic/i-029848aa687347ecd
1709608297538,"2024-03-05T03:11:37,438 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stdout",AllTraffic/i-029848aa687347ecd
1709608300044,"2024-03-05T03:11:37,438 [INFO ] W-9000-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stderr",AllTraffic/i-029848aa687347ecd
1709608300044,"2024-03-05T03:11:39,825 [INFO ] pool-2-thread-2 ACCESS_LOG - /169.254.178.2:57068 ""GET /ping HTTP/1.1"" 200 1",AllTraffic/i-029848aa687347ecd
1709608300797,"2024-03-05T03:11:39,825 [INFO ] pool-2-thread-2 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:container-0.local,timestamp:1709608299",AllTraffic/i-029848aa687347ecd
1709608300797,"2024-03-05T03:11:40,565 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9000, pid=580",AllTraffic/i-029848aa687347ecd
1709608300797,"2024-03-05T03:11:40,566 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000",AllTraffic/i-029848aa687347ecd
1709608300797,"2024-03-05T03:11:40,582 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.",AllTraffic/i-029848aa687347ecd
1709608300797,"2024-03-05T03:11:40,583 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - [PID]580",AllTraffic/i-029848aa687347ecd
1709608300797,"2024-03-05T03:11:40,583 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Torch worker started.",AllTraffic/i-029848aa687347ecd
1709608300797,"2024-03-05T03:11:40,583 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9",AllTraffic/i-029848aa687347ecd
1709608300797,"2024-03-05T03:11:40,583 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000",AllTraffic/i-029848aa687347ecd
1709608300797,"2024-03-05T03:11:40,585 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED",AllTraffic/i-029848aa687347ecd
1709608300797,"2024-03-05T03:11:40,586 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again",AllTraffic/i-029848aa687347ecd
1709608300797,"2024-03-05T03:11:40,586 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.",AllTraffic/i-029848aa687347ecd
1709608300797,"2024-03-05T03:11:40,586 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stderr",AllTraffic/i-029848aa687347ecd
1709608300797,"2024-03-05T03:11:40,586 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stdout",AllTraffic/i-029848aa687347ecd
1709608300797,"2024-03-05T03:11:40,586 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 8 seconds.",AllTraffic/i-029848aa687347ecd
1709608304053,"2024-03-05T03:11:40,586 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stdout",AllTraffic/i-029848aa687347ecd
1709608305055,"2024-03-05T03:11:43,838 [INFO ] W-9000-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stderr",AllTraffic/i-029848aa687347ecd
1709608305055,"2024-03-05T03:11:44,824 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.178.2:57068 ""GET /ping HTTP/1.1"" 200 0",AllTraffic/i-029848aa687347ecd
1709608309744,"2024-03-05T03:11:44,825 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:container-0.local,timestamp:1709608304",AllTraffic/i-029848aa687347ecd
1709608310071,"2024-03-05T03:11:49,824 [INFO ] pool-2-thread-2 ACCESS_LOG - /169.254.178.2:57068 ""GET /ping HTTP/1.1"" 200 0",AllTraffic/i-029848aa687347ecd
1709608310071,"2024-03-05T03:11:49,825 [INFO ] pool-2-thread-2 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:container-0.local,timestamp:1709608309",AllTraffic/i-029848aa687347ecd
1709608310071,"2024-03-05T03:11:49,955 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9000, pid=592",AllTraffic/i-029848aa687347ecd
1709608310071,"2024-03-05T03:11:49,955 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000",AllTraffic/i-029848aa687347ecd
1709608310071,"2024-03-05T03:11:49,972 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.",AllTraffic/i-029848aa687347ecd
1709608310071,"2024-03-05T03:11:49,973 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - [PID]592",AllTraffic/i-029848aa687347ecd
1709608310071,"2024-03-05T03:11:49,973 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Torch worker started.",AllTraffic/i-029848aa687347ecd
1709608310071,"2024-03-05T03:11:49,973 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9",AllTraffic/i-029848aa687347ecd
1709608310071,"2024-03-05T03:11:49,973 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000",AllTraffic/i-029848aa687347ecd
1709608310071,"2024-03-05T03:11:49,975 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.",AllTraffic/i-029848aa687347ecd
1709608310071,"2024-03-05T03:11:49,975 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED",AllTraffic/i-029848aa687347ecd
1709608310071,"2024-03-05T03:11:49,976 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again",AllTraffic/i-029848aa687347ecd
1709608310071,"2024-03-05T03:11:49,976 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stderr",AllTraffic/i-029848aa687347ecd
1709608310071,"2024-03-05T03:11:49,976 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stdout",AllTraffic/i-029848aa687347ecd
1709608313331,"2024-03-05T03:11:49,976 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 13 seconds.",AllTraffic/i-029848aa687347ecd
1709608313331,"2024-03-05T03:11:53,220 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stdout",AllTraffic/i-029848aa687347ecd
1709608314835,"2024-03-05T03:11:53,220 [INFO ] W-9000-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stderr",AllTraffic/i-029848aa687347ecd
1709608314835,"2024-03-05T03:11:54,824 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.178.2:57068 ""GET /ping HTTP/1.1"" 200 0",AllTraffic/i-029848aa687347ecd
1709608319745,"2024-03-05T03:11:54,825 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:container-0.local,timestamp:1709608314",AllTraffic/i-029848aa687347ecd
1709608319849,"2024-03-05T03:11:59,824 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.178.2:57068 ""GET /ping HTTP/1.1"" 200 0",AllTraffic/i-029848aa687347ecd
1709608324360,"2024-03-05T03:11:59,825 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:container-0.local,timestamp:1709608319",AllTraffic/i-029848aa687347ecd
1709608324360,"2024-03-05T03:12:04,322 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9000, pid=604",AllTraffic/i-029848aa687347ecd
1709608324360,"2024-03-05T03:12:04,323 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000",AllTraffic/i-029848aa687347ecd
1709608324360,"2024-03-05T03:12:04,339 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.",AllTraffic/i-029848aa687347ecd
1709608324360,"2024-03-05T03:12:04,340 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - [PID]604",AllTraffic/i-029848aa687347ecd
1709608324360,"2024-03-05T03:12:04,341 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Torch worker started.",AllTraffic/i-029848aa687347ecd
1709608324360,"2024-03-05T03:12:04,341 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000",AllTraffic/i-029848aa687347ecd
1709608324360,"2024-03-05T03:12:04,341 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9",AllTraffic/i-029848aa687347ecd
1709608324360,"2024-03-05T03:12:04,342 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED",AllTraffic/i-029848aa687347ecd
1709608324360,"2024-03-05T03:12:04,342 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.",AllTraffic/i-029848aa687347ecd
1709608324360,"2024-03-05T03:12:04,343 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again",AllTraffic/i-029848aa687347ecd
1709608324360,"2024-03-05T03:12:04,343 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stderr",AllTraffic/i-029848aa687347ecd
1709608324360,"2024-03-05T03:12:04,343 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stdout",AllTraffic/i-029848aa687347ecd
1709608324862,"2024-03-05T03:12:04,350 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 21 seconds.",AllTraffic/i-029848aa687347ecd
1709608324862,"2024-03-05T03:12:04,824 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.178.2:57068 ""GET /ping HTTP/1.1"" 200 0",AllTraffic/i-029848aa687347ecd
1709608327619,"2024-03-05T03:12:04,824 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:container-0.local,timestamp:1709608324",AllTraffic/i-029848aa687347ecd
1709608327619,"2024-03-05T03:12:07,582 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stdout",AllTraffic/i-029848aa687347ecd
1709608329874,"2024-03-05T03:12:07,582 [INFO ] W-9000-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stderr",AllTraffic/i-029848aa687347ecd
1709608329874,"2024-03-05T03:12:09,824 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.178.2:57068 ""GET /ping HTTP/1.1"" 200 0",AllTraffic/i-029848aa687347ecd
1709608334745,"2024-03-05T03:12:09,824 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:container-0.local,timestamp:1709608329",AllTraffic/i-029848aa687347ecd
1709608334891,"2024-03-05T03:12:14,824 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.178.2:57068 ""GET /ping HTTP/1.1"" 200 0",AllTraffic/i-029848aa687347ecd
1709608339744,"2024-03-05T03:12:14,824 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:container-0.local,timestamp:1709608334",AllTraffic/i-029848aa687347ecd
1709608339909,"2024-03-05T03:12:19,824 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.178.2:57068 ""GET /ping HTTP/1.1"" 200 0",AllTraffic/i-029848aa687347ecd
1709608344676,"2024-03-05T03:12:19,825 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:container-0.local,timestamp:1709608339",AllTraffic/i-029848aa687347ecd
1709608344926,"2024-03-05T03:12:24,434 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:container-0.local,timestamp:1709608344",AllTraffic/i-029848aa687347ecd
1709608344926,"2024-03-05T03:12:24,835 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.178.2:54910 ""GET /ping HTTP/1.1"" 200 0",AllTraffic/i-029848aa687347ecd
1709608346932,"2024-03-05T03:12:24,835 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:container-0.local,timestamp:1709608344",AllTraffic/i-029848aa687347ecd
1709608346932,"2024-03-05T03:12:26,694 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9000, pid=618",AllTraffic/i-029848aa687347ecd
1709608346932,"2024-03-05T03:12:26,695 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000",AllTraffic/i-029848aa687347ecd
1709608346932,"2024-03-05T03:12:26,705 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.",AllTraffic/i-029848aa687347ecd
1709608346932,"2024-03-05T03:12:26,705 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - [PID]618",AllTraffic/i-029848aa687347ecd
1709608346932,"2024-03-05T03:12:26,706 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000",AllTraffic/i-029848aa687347ecd
1709608346932,"2024-03-05T03:12:26,706 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Torch worker started.",AllTraffic/i-029848aa687347ecd
1709608346932,"2024-03-05T03:12:26,707 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9",AllTraffic/i-029848aa687347ecd
1709608346932,"2024-03-05T03:12:26,708 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED",AllTraffic/i-029848aa687347ecd
1709608346932,"2024-03-05T03:12:26,708 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1709608346708",AllTraffic/i-029848aa687347ecd
1709608346932,"2024-03-05T03:12:26,708 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.",AllTraffic/i-029848aa687347ecd
1709608346932,"2024-03-05T03:12:26,710 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.178.2:57068 ""POST /invocations HTTP/1.1"" 500 2281",AllTraffic/i-029848aa687347ecd
1709608346932,"2024-03-05T03:12:26,711 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1.0|#Level:Host|#hostname:container-0.local,timestamp:1709608346",AllTraffic/i-029848aa687347ecd
1709608346932,"2024-03-05T03:12:26,711 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again",AllTraffic/i-029848aa687347ecd
1709608346932,"2024-03-05T03:12:26,712 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stderr",AllTraffic/i-029848aa687347ecd
1709608346932,"2024-03-05T03:12:26,712 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stdout",AllTraffic/i-029848aa687347ecd
1709608349944,"2024-03-05T03:12:26,712 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 34 seconds.",AllTraffic/i-029848aa687347ecd
1709608349944,"2024-03-05T03:12:29,824 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.178.2:54910 ""GET /ping HTTP/1.1"" 200 0",AllTraffic/i-029848aa687347ecd
1709608350191,"2024-03-05T03:12:29,824 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:container-0.local,timestamp:1709608349",AllTraffic/i-029848aa687347ecd
1709608350191,"2024-03-05T03:12:29,962 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stdout",AllTraffic/i-029848aa687347ecd
1709608354745,"2024-03-05T03:12:29,962 [INFO ] W-9000-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stderr",AllTraffic/i-029848aa687347ecd
1709608354956,"2024-03-05T03:12:34,824 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.178.2:54910 ""GET /ping HTTP/1.1"" 200 0",AllTraffic/i-029848aa687347ecd
1709608359745,"2024-03-05T03:12:34,824 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:container-0.local,timestamp:1709608354",AllTraffic/i-029848aa687347ecd
1709608359968,"2024-03-05T03:12:39,824 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.178.2:54910 ""GET /ping HTTP/1.1"" 200 0",AllTraffic/i-029848aa687347ecd
1709608364745,"2024-03-05T03:12:39,824 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:container-0.local,timestamp:1709608359",AllTraffic/i-029848aa687347ecd
1709608364984,"2024-03-05T03:12:44,824 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.178.2:54910 ""GET /ping HTTP/1.1"" 200 0",AllTraffic/i-029848aa687347ecd
1709608369745,"2024-03-05T03:12:44,825 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:container-0.local,timestamp:1709608364",AllTraffic/i-029848aa687347ecd
1709608369998,"2024-03-05T03:12:49,824 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.178.2:54910 ""GET /ping HTTP/1.1"" 200 0",AllTraffic/i-029848aa687347ecd
1709608374745,"2024-03-05T03:12:49,825 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:container-0.local,timestamp:1709608369",AllTraffic/i-029848aa687347ecd
1709608375016,"2024-03-05T03:12:54,824 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.178.2:54910 ""GET /ping HTTP/1.1"" 200 0",AllTraffic/i-029848aa687347ecd
1709608379745,"2024-03-05T03:12:54,824 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:container-0.local,timestamp:1709608374",AllTraffic/i-029848aa687347ecd
1709608380027,"2024-03-05T03:12:59,824 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.178.2:54910 ""GET /ping HTTP/1.1"" 200 0",AllTraffic/i-029848aa687347ecd
1709608382282,"2024-03-05T03:12:59,824 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:container-0.local,timestamp:1709608379",AllTraffic/i-029848aa687347ecd
1709608382282,"2024-03-05T03:13:02,084 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9000, pid=630",AllTraffic/i-029848aa687347ecd
1709608382282,"2024-03-05T03:13:02,085 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000",AllTraffic/i-029848aa687347ecd
1709608382282,"2024-03-05T03:13:02,102 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.",AllTraffic/i-029848aa687347ecd
1709608382282,"2024-03-05T03:13:02,102 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - [PID]630",AllTraffic/i-029848aa687347ecd
1709608382282,"2024-03-05T03:13:02,102 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Torch worker started.",AllTraffic/i-029848aa687347ecd
1709608382282,"2024-03-05T03:13:02,102 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9",AllTraffic/i-029848aa687347ecd
1709608382282,"2024-03-05T03:13:02,103 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000",AllTraffic/i-029848aa687347ecd
1709608382282,"2024-03-05T03:13:02,104 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED",AllTraffic/i-029848aa687347ecd
1709608382282,"2024-03-05T03:13:02,104 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.",AllTraffic/i-029848aa687347ecd
1709608382282,"2024-03-05T03:13:02,104 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again",AllTraffic/i-029848aa687347ecd
1709608382282,"2024-03-05T03:13:02,105 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stderr",AllTraffic/i-029848aa687347ecd
1709608382282,"2024-03-05T03:13:02,105 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stdout",AllTraffic/i-029848aa687347ecd
1709608385051,"2024-03-05T03:13:02,105 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 55 seconds.",AllTraffic/i-029848aa687347ecd
1709608385051,"2024-03-05T03:13:04,824 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.178.2:54910 ""GET /ping HTTP/1.1"" 200 0",AllTraffic/i-029848aa687347ecd
1709608385541,"2024-03-05T03:13:04,824 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:container-0.local,timestamp:1709608384",AllTraffic/i-029848aa687347ecd
1709608385541,"2024-03-05T03:13:05,349 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stdout",AllTraffic/i-029848aa687347ecd
1709608389745,"2024-03-05T03:13:05,349 [INFO ] W-9000-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stderr",AllTraffic/i-029848aa687347ecd
1709608390072,"2024-03-05T03:13:09,824 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.178.2:54910 ""GET /ping HTTP/1.1"" 200 0",AllTraffic/i-029848aa687347ecd
1709608394744,"2024-03-05T03:13:09,824 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:container-0.local,timestamp:1709608389",AllTraffic/i-029848aa687347ecd
1709608395064,"2024-03-05T03:13:14,824 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.178.2:54910 ""GET /ping HTTP/1.1"" 200 0",AllTraffic/i-029848aa687347ecd
1709608399745,"2024-03-05T03:13:14,825 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:container-0.local,timestamp:1709608394",AllTraffic/i-029848aa687347ecd
1709608399830,"2024-03-05T03:13:19,824 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.178.2:54910 ""GET /ping HTTP/1.1"" 200 0",AllTraffic/i-029848aa687347ecd
1709608404744,"2024-03-05T03:13:19,824 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:container-0.local,timestamp:1709608399",AllTraffic/i-029848aa687347ecd
1709608404844,"2024-03-05T03:13:24,824 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.178.2:54910 ""GET /ping HTTP/1.1"" 200 0",AllTraffic/i-029848aa687347ecd
1709608409745,"2024-03-05T03:13:24,824 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:container-0.local,timestamp:1709608404",AllTraffic/i-029848aa687347ecd
1709608409856,"2024-03-05T03:13:29,824 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.178.2:54910 ""GET /ping HTTP/1.1"" 200 0",AllTraffic/i-029848aa687347ecd
1709608414745,"2024-03-05T03:13:29,824 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:container-0.local,timestamp:1709608409",AllTraffic/i-029848aa687347ecd
1709608414882,"2024-03-05T03:13:34,824 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.178.2:54910 ""GET /ping HTTP/1.1"" 200 0",AllTraffic/i-029848aa687347ecd
1709608419745,"2024-03-05T03:13:34,825 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:container-0.local,timestamp:1709608414",AllTraffic/i-029848aa687347ecd
1709608419896,"2024-03-05T03:13:39,824 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.178.2:54910 ""GET /ping HTTP/1.1"" 200 0",AllTraffic/i-029848aa687347ecd
1709608424745,"2024-03-05T03:13:39,824 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:container-0.local,timestamp:1709608419",AllTraffic/i-029848aa687347ecd
1709608424911,"2024-03-05T03:13:44,824 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.178.2:54910 ""GET /ping HTTP/1.1"" 200 0",AllTraffic/i-029848aa687347ecd
1709608429745,"2024-03-05T03:13:44,825 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:container-0.local,timestamp:1709608424",AllTraffic/i-029848aa687347ecd
1709608429929,"2024-03-05T03:13:49,824 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.178.2:54910 ""GET /ping HTTP/1.1"" 200 0",AllTraffic/i-029848aa687347ecd
1709608434745,"2024-03-05T03:13:49,824 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:container-0.local,timestamp:1709608429",AllTraffic/i-029848aa687347ecd
1709608434943,"2024-03-05T03:13:54,824 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.178.2:54910 ""GET /ping HTTP/1.1"" 200 0",AllTraffic/i-029848aa687347ecd
1709608438697,"2024-03-05T03:13:54,824 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:container-0.local,timestamp:1709608434",AllTraffic/i-029848aa687347ecd
1709608438697,"2024-03-05T03:13:58,454 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9000, pid=642",AllTraffic/i-029848aa687347ecd
1709608438697,"2024-03-05T03:13:58,456 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000",AllTraffic/i-029848aa687347ecd
1709608438697,"2024-03-05T03:13:58,471 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.",AllTraffic/i-029848aa687347ecd
1709608438697,"2024-03-05T03:13:58,471 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - [PID]642",AllTraffic/i-029848aa687347ecd
1709608438697,"2024-03-05T03:13:58,472 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Torch worker started.",AllTraffic/i-029848aa687347ecd
1709608438697,"2024-03-05T03:13:58,472 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9",AllTraffic/i-029848aa687347ecd
1709608438697,"2024-03-05T03:13:58,472 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000",AllTraffic/i-029848aa687347ecd
1709608438697,"2024-03-05T03:13:58,472 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED",AllTraffic/i-029848aa687347ecd
1709608438697,"2024-03-05T03:13:58,473 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.",AllTraffic/i-029848aa687347ecd
1709608438697,"2024-03-05T03:13:58,473 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again",AllTraffic/i-029848aa687347ecd
1709608438697,"2024-03-05T03:13:58,473 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stderr",AllTraffic/i-029848aa687347ecd
1709608438697,"2024-03-05T03:13:58,473 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stdout",AllTraffic/i-029848aa687347ecd
1709608439955,"2024-03-05T03:13:58,473 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 89 seconds.",AllTraffic/i-029848aa687347ecd
1709608439955,"2024-03-05T03:13:59,824 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.178.2:54910 ""GET /ping HTTP/1.1"" 200 0",AllTraffic/i-029848aa687347ecd
1709608441955,"2024-03-05T03:13:59,825 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:container-0.local,timestamp:1709608439",AllTraffic/i-029848aa687347ecd
1709608441955,"2024-03-05T03:14:01,718 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stdout",AllTraffic/i-029848aa687347ecd
1709608444968,"2024-03-05T03:14:01,718 [INFO ] W-9000-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stderr",AllTraffic/i-029848aa687347ecd
1709608444968,"2024-03-05T03:14:04,824 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.178.2:54910 ""GET /ping HTTP/1.1"" 200 0",AllTraffic/i-029848aa687347ecd
1709608449745,"2024-03-05T03:14:04,824 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:container-0.local,timestamp:1709608444",AllTraffic/i-029848aa687347ecd
1709608449981,"2024-03-05T03:14:09,824 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.178.2:54910 ""GET /ping HTTP/1.1"" 200 0",AllTraffic/i-029848aa687347ecd
1709608454745,"2024-03-05T03:14:09,824 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:container-0.local,timestamp:1709608449",AllTraffic/i-029848aa687347ecd
1709608455006,"2024-03-05T03:14:14,824 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.178.2:54910 ""GET /ping HTTP/1.1"" 200 0",AllTraffic/i-029848aa687347ecd
1709608459744,"2024-03-05T03:14:14,825 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:container-0.local,timestamp:1709608454",AllTraffic/i-029848aa687347ecd
1709608460004,"2024-03-05T03:14:19,824 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.178.2:54910 ""GET /ping HTTP/1.1"" 200 0",AllTraffic/i-029848aa687347ecd
1709608464745,"2024-03-05T03:14:19,824 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:container-0.local,timestamp:1709608459",AllTraffic/i-029848aa687347ecd
1709608465016,"2024-03-05T03:14:24,824 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.178.2:54910 ""GET /ping HTTP/1.1"" 200 0",AllTraffic/i-029848aa687347ecd
1709608469791,"2024-03-05T03:14:24,824 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:container-0.local,timestamp:1709608464",AllTraffic/i-029848aa687347ecd
1709608470029,"2024-03-05T03:14:29,824 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.178.2:54910 ""GET /ping HTTP/1.1"" 200 0",AllTraffic/i-029848aa687347ecd
1709608474745,"2024-03-05T03:14:29,824 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:container-0.local,timestamp:1709608469",AllTraffic/i-029848aa687347ecd
1709608475043,"2024-03-05T03:14:34,824 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.178.2:54910 ""GET /ping HTTP/1.1"" 200 0",AllTraffic/i-029848aa687347ecd
1709608479745,"2024-03-05T03:14:34,824 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:container-0.local,timestamp:1709608474",AllTraffic/i-029848aa687347ecd
1709608480058,"2024-03-05T03:14:39,824 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.178.2:54910 ""GET /ping HTTP/1.1"" 200 0",AllTraffic/i-029848aa687347ecd
1709608484745,"2024-03-05T03:14:39,824 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:container-0.local,timestamp:1709608479",AllTraffic/i-029848aa687347ecd
1709608485081,"2024-03-05T03:14:44,824 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.178.2:54910 ""GET /ping HTTP/1.1"" 200 0",AllTraffic/i-029848aa687347ecd
1709608489745,"2024-03-05T03:14:44,824 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:container-0.local,timestamp:1709608484",AllTraffic/i-029848aa687347ecd
1709608489835,"2024-03-05T03:14:49,824 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.178.2:54910 ""GET /ping HTTP/1.1"" 200 0",AllTraffic/i-029848aa687347ecd
1709608494745,"2024-03-05T03:14:49,824 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:container-0.local,timestamp:1709608489",AllTraffic/i-029848aa687347ecd
1709608494847,"2024-03-05T03:14:54,824 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.178.2:54910 ""GET /ping HTTP/1.1"" 200 0",AllTraffic/i-029848aa687347ecd
1709608499783,"2024-03-05T03:14:54,824 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:container-0.local,timestamp:1709608494",AllTraffic/i-029848aa687347ecd
1709608499860,"2024-03-05T03:14:59,824 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.178.2:54910 ""GET /ping HTTP/1.1"" 200 0",AllTraffic/i-029848aa687347ecd
1709608504745,"2024-03-05T03:14:59,824 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:container-0.local,timestamp:1709608499",AllTraffic/i-029848aa687347ecd
1709608504871,"2024-03-05T03:15:04,824 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.178.2:54910 ""GET /ping HTTP/1.1"" 200 0",AllTraffic/i-029848aa687347ecd
1709608509745,"2024-03-05T03:15:04,824 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:container-0.local,timestamp:1709608504",AllTraffic/i-029848aa687347ecd
1709608509886,"2024-03-05T03:15:09,824 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.178.2:54910 ""GET /ping HTTP/1.1"" 200 0",AllTraffic/i-029848aa687347ecd
1709608514745,"2024-03-05T03:15:09,824 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:container-0.local,timestamp:1709608509",AllTraffic/i-029848aa687347ecd